apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-worker
  namespace: azuredocs-app
  labels:
    app: llm-worker
    component: worker
spec:
  # replicas managed by KEDA ScaledObject
  selector:
    matchLabels:
      app: llm-worker
  template:
    metadata:
      labels:
        app: llm-worker
        component: worker
        azure.workload.identity/use: "true"
    spec:
      priorityClassName: worker-normal-priority
      serviceAccountName: azuredocs-app-sa
      terminationGracePeriodSeconds: 120  # Longer for LLM calls
      containers:
      - name: llm-worker
        image: seanmckdemo.azurecr.io/queue-worker
        imagePullPolicy: Always
        command: ["python", "worker/llm_scoring_worker.py"]
        env:
        - name: ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: azuredocs-secrets
              key: ADMIN_PASSWORD
        - name: ADMIN_USERNAME
          valueFrom:
            secretKeyRef:
              name: azuredocs-secrets
              key: ADMIN_USERNAME
        - name: APP_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: azuredocs-secrets
              key: APP_SECRET_KEY
        - name: PYTHONPATH
          value: "/app"
        - name: RABBITMQ_HOST
          value: "rabbitmq"
        - name: RABBITMQ_PORT
          value: "5672"
        - name: RABBITMQ_USERNAME
          valueFrom:
            secretKeyRef:
              name: azuredocs-secrets
              key: RABBITMQ_USERNAME
        - name: RABBITMQ_PASSWORD
          valueFrom:
            secretKeyRef:
              name: azuredocs-secrets
              key: RABBITMQ_PASSWORD
        - name: GITHUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: azuredocs-secrets
              key: GITHUB_TOKEN
        - name: AZURE_OPENAI_DEPLOYMENT
          value: "gpt-4.1"
        - name: MCP_SERVER_URL
          value: "http://bias-scoring-service:9000/score_page"
        envFrom:
        - secretRef:
            name: sc-azuredocsdbconnection-secret
        - secretRef:
            name: sc-linuxdocsazureopenai-secret
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - python
            - -c
            - "import sys; sys.exit(0)"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          exec:
            command:
            - python
            - -c
            - "import sys; sys.exit(0)"
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        volumeMounts:
        - name: secrets-store
          mountPath: "/mnt/secrets-store"
          readOnly: true
      volumes:
      - name: secrets-store
        csi:
          driver: secrets-store.csi.k8s.io
          readOnly: true
          volumeAttributes:
            secretProviderClass: "azuredocs-secrets"
      restartPolicy: Always
      nodeSelector:
        karpenter.sh/capacity-type: spot
---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: llm-worker-scaler
  namespace: azuredocs-app
spec:
  scaleTargetRef:
    name: llm-worker
  minReplicaCount: 0
  maxReplicaCount: 2  # Limited by LLM rate limit
  cooldownPeriod: 300
  triggers:
  - type: rabbitmq
    metadata:
      queueName: llm_scoring
      mode: QueueLength
      value: "5"  # Scale up when queue has 5+ messages
      excludeUnacknowledged: "false"
    authenticationRef:
      name: rabbitmq-trigger-auth
